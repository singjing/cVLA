{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = \"/tmp/clevr-act-1\"\n",
    "print(\"Train set:\")\n",
    "!head -n 5 {dataset_location}/dataset/_annotations.train.jsonl\n",
    "print(\"\\nValidation set:\")\n",
    "!head -n 5 {dataset_location}/dataset/_annotations.valid.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import supervision as sv\n",
    "from typing import List\n",
    "import re\n",
    "\n",
    "def read_n_lines(file_path: str, n: int) -> List[str]:\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = [next(file).strip() for _ in range(n)]\n",
    "    return lines\n",
    "\n",
    "def parse_trajectory_tokens(caption):\n",
    "  caption = caption.strip(\"\\n\")\n",
    "  if \";\" in caption:\n",
    "    raise ValueError\n",
    "  pattern = r\"(?:<loc\\d{4}>)+ ([\\w\\s\\-]+)$\"\n",
    "  match = re.search(pattern, caption)\n",
    "  #print(f\"Matched words: {match.group(1)}\")\n",
    "  if match:\n",
    "    return match\n",
    "  else:\n",
    "    return \"\"\n",
    "\n",
    "images = []\n",
    "lines = read_n_lines(f\"{dataset_location}/dataset/_annotations.train.jsonl\", 25)\n",
    "first = json.loads(lines[0])\n",
    "\n",
    "#CLASSES = first.get('prefix').replace(\"detect \", \"\").split(\" ; \")\n",
    "for line in lines:\n",
    "    data = json.loads(line)\n",
    "    #image = cv2.imread(f\"{dataset_location}/dataset/{data.get('image')}\")\n",
    "    #(h, w, _) = image.shape\n",
    "\n",
    "    suffix = data.get('suffix')\n",
    "    prefix = data.get('prefix')\n",
    "    #match = parse_trajectory_tokens(suffix)\n",
    "    print(prefix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "import html\n",
    "import base64\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "text = \"<loc0625><loc0762><loc0468><loc0724><loc0384><loc0679><loc0375><loc0632><loc0430><loc0587><loc0587> 1\"\n",
    "action_text = data.get('prefix')\n",
    "\n",
    "def render_example_trajectory(image, caption):\n",
    "    # Pattern to extract numbers inside <loc####> tags\n",
    "    loc_strings = re.findall(r\"<loc(\\d{4})>\", caption)\n",
    "    num_position_tokens = len(loc_strings)\n",
    "    loc_strings_pairs = loc_strings[:(num_position_tokens//2)*2]\n",
    "    loc_numbers = [int(x) for x in loc_strings_pairs]\n",
    "    loc_h = [x/1024*image_height for x in loc_numbers[::2]]\n",
    "    loc_w = [x/1024*image_width for x in loc_numbers[1::2]]\n",
    "    curve_2d_short = curve_2d = np.array([np.stack((loc_w, loc_h), axis=1)])\n",
    "\n",
    "    env_id = 0\n",
    "    x, y = curve_2d[env_id, :, 0].tolist(), curve_2d[env_id, :, 1].tolist()\n",
    "\n",
    "    pixel_width, pixel_height = 448, 448\n",
    "    dpi = 100\n",
    "    figsize = (pixel_width / dpi, pixel_height / dpi)\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    ax.plot(curve_2d_short[env_id,:,0], curve_2d_short[env_id, :,1],'.-', color='lime')\n",
    "    with io.BytesIO() as buffer:\n",
    "        fig.savefig(buffer, format='jpeg',bbox_inches='tight', dpi=dpi)\n",
    "        image_b64 = str(base64.b64encode(buffer.getvalue()), \"utf-8\")\n",
    "        res_str =  f\"data:image/jpeg;base64,{image_b64}\"\n",
    "    plt.close(fig)\n",
    "    return f\"\"\"\n",
    "<div style=\"display: inline-flex; align-items: center; justify-content: center;\">\n",
    "    <img style=\"width:224px; height:224px;\" src=\"{res_str}\" />\n",
    "    <p style=\"width:256px; margin:10px; font-size:small;\">{html.escape(caption)}</br>{html.escape(caption)}</p>\n",
    "\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "html_out = \"\"\n",
    "#for image, _, caption in make_predictions(validation_data_iterator(), num_examples=1, batch_size=1):\n",
    "#  html_out += render_example(image, caption)\n",
    "\n",
    "caption = data.get('prefix')\n",
    "image = Image.open(f\"{dataset_location}/dataset/{data.get('image')}\")\n",
    "html_out += render_example_trajectory(image, caption)\n",
    "display(HTML(html_out))\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paligemma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
