{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%pip install torchvision\n",
    "import random\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from cvla.data_loader_h5 import H5Dataset\n",
    "from cvla.data_loader_jsonl import JSONLDataset\n",
    "from cvla.data_augmentations import augment_image_rgb, RandomizeBackgrounds\n",
    "import torchvision.transforms\n",
    "\n",
    "\n",
    "\n",
    "dataset_location = Path(\"/tmp/clevr-act-7-depth\")\n",
    "real_image_size = 720, 1280\n",
    "resize_cropper = torchvision.transforms.RandomResizedCrop(size=real_image_size, scale=(0.9, 1.0),)\n",
    "jsonl_file_path = Path(\"/data/lmbraid19/argusm/datasets/cvla-droid-1of5c-v1/_annotations.train.jsonl\")\n",
    "bg_img_dataset = JSONLDataset(jsonl_file_path=jsonl_file_path, augment_rgb=resize_cropper)\n",
    "train_dataset = bg_img_dataset\n",
    "randomize_background = RandomizeBackgrounds(p=0.2, background_images = bg_img_dataset)\n",
    "\n",
    "#randomize_background = RandomizeBackgrounds(p=0.2, background_images_path = \"/data/lmbraid19/argusm/datasets/indoorCVPR/Images\")\n",
    "train_dataset = H5Dataset(dataset_location, augment_rgbds=randomize_background, augment_rgb=augment_image_rgb)\n",
    "print(\"load done.\")\n",
    "\n",
    "r,c = 2,4\n",
    "fig, axes = plt.subplots(r, c, figsize=(c*4, r*4))\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        random_idx = random.choice(range(len(train_dataset)))\n",
    "        image = train_dataset[random_idx][0]\n",
    "        ax = axes[i][j]\n",
    "        ax.axis(\"off\")\n",
    "        ax.imshow(image)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Real Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "dataset_location = \"/data/lmbraid19/argusm/datasets/cvla-droid-block-v1\"\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from cvla.utils_vis import render_example\n",
    "from cvla.utils_trajectory import DummyCamera\n",
    "from cvla.data_loader_jsonl import JSONLDataset\n",
    "\n",
    "test_dataset = JSONLDataset(\n",
    "    jsonl_file_path=f\"{dataset_location}/_annotations.valid.jsonl\",\n",
    "    image_directory_path=f\"{dataset_location}/dataset\",\n",
    ")\n",
    "\n",
    "test_samples = 10#len(test_dataset)\n",
    "decode_dataset = [None, ]*test_samples\n",
    "pred_list = []\n",
    "html_imgs = \"\"\n",
    "\n",
    "for i in tqdm(range(test_samples), total=test_samples):\n",
    "    image, sample = test_dataset[i]\n",
    "\n",
    "    html_img = render_example(image, label=sample[\"suffix\"], text=sample[\"prefix\"], camera=sample[\"camera\"])\n",
    "    html_imgs += html_img\n",
    "\n",
    "plot_images = True\n",
    "if plot_images:\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(html_imgs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
