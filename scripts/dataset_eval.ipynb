{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Datasets\n",
    "\n",
    "Compare two datasets to make sure they are reasonably similar.\n",
    "\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from cvla.data_loader import JSONLDataset\n",
    "\n",
    "ACTION_ENCODER = \"xyzrotvec-cam-proj\"\n",
    "\n",
    "real_dataset_location = \"/data/lmbraid19/argusm/datasets/clevr-real-block-v1\"\n",
    "real_dataset_location = Path(real_dataset_location)\n",
    "real_dataset = JSONLDataset(\n",
    "    jsonl_file_path=f\"{real_dataset_location}/dataset/_annotations.valid.jsonl\",\n",
    "    image_directory_path=f\"{real_dataset_location}/dataset\",\n",
    ")\n",
    "sim_dataset_location = \"/data/lmbraid19/argusm/datasets/clevr-act-6-var-cam\"\n",
    "sim_dataset_location = Path(sim_dataset_location)\n",
    "sim_dataset = JSONLDataset(\n",
    "    jsonl_file_path=f\"{sim_dataset_location}/dataset/_annotations.valid.jsonl\",\n",
    "    image_directory_path=f\"{sim_dataset_location}/dataset\",\n",
    ")\n",
    "\n",
    "pred_list = []\n",
    "valid_sample = []\n",
    "\n",
    "num_samples = len(real_dataset)\n",
    "suffix_rs = []\n",
    "suffix_ss = []\n",
    "for i in tqdm(range(num_samples)):\n",
    "    image_r, label_real = real_dataset[i]\n",
    "    image_s, label_sim = sim_dataset[i]\n",
    "    suffix_real = [int(x) for x in re.findall(r\"<loc(\\d{4})>\", label_real[\"suffix\"])]\n",
    "    suffix_sim = [int(x) for x in re.findall(r\"<loc(\\d{4})>\", label_sim[\"suffix\"])]\n",
    "    suffix_rs.append(suffix_real)\n",
    "    suffix_ss.append(suffix_sim)\n",
    "\n",
    "suffix_rs = np.array(suffix_rs)\n",
    "suffix_ss = np.array(suffix_ss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Raw Value Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 12*1/3))  # 3 rows x 4 columns of histograms\n",
    "\n",
    "names = \"real\", \"sim\"\n",
    "data = (suffix_rs, suffix_ss)\n",
    "for i in range(2):\n",
    "    i=i+0\n",
    "    axes[0].scatter(data[i][:,0], data[i][:,1], alpha=0.7, label=names[i])\n",
    "    axes[0].scatter(data[i][:,6], data[i][:,7], alpha=0.7, label=names[i]+\"-dst\")\n",
    "    axes[0].legend()\n",
    "    axes[1].hist(data[i][:,2],  bins=10, alpha=0.5,  edgecolor='black',label=names[i])\n",
    "    axes[1].hist(data[i][:,2+6],  bins=10, alpha=0.5,  edgecolor='black',label=names[i]+\"-dst\")\n",
    "    axes[1].legend()\n",
    "    \n",
    "#axes[0].set_title(f'Hist {action_labels[i]}')\n",
    "#axes[0].set_xlabel(units[i])\n",
    "#axes[0].set_ylabel('Frequency')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_components(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    verb, obj, prep, prep_obj = None, None, None, None\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":  # Extract the main verb\n",
    "            verb = token.text\n",
    "        elif token.dep_ == \"dobj\":  # Extract direct object\n",
    "            obj = token.text\n",
    "        elif token.dep_ == \"prep\":  # Extract preposition\n",
    "            prep = token.text\n",
    "        elif token.dep_ == \"pobj\":  # Extract prepositional object\n",
    "            prep_obj = token.text\n",
    "\n",
    "    return dict(verb=verb, obj=obj, prep=prep, prep_obj=prep_obj)\n",
    "\n",
    "list_of_comp_real = []\n",
    "list_of_comp_sim = []\n",
    "texts = []\n",
    "num_samples = len(real_dataset)\n",
    "for i in tqdm(range(num_samples)):\n",
    "    image_r, label_real = real_dataset[i]\n",
    "    text_real = label_real[\"prefix\"].split(\"<\")[0].replace(\"\\n\",\"\").lower()\n",
    "    components_real = extract_components(text_real)\n",
    "    list_of_comp_real.append(components_real)\n",
    "    texts.append(text_real)\n",
    "\n",
    "    image_s, label_sim = sim_dataset[i]\n",
    "    text_sim = label_sim[\"prefix\"].split(\"<\")[0]\n",
    "    components_sim = extract_components(text_sim)\n",
    "    list_of_comp_sim.append(components_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def count_value_frequencies(list_of_dicts):\n",
    "    key_value_counter = defaultdict(Counter)\n",
    "    \n",
    "    # Iterate through each dictionary\n",
    "    for d in list_of_dicts:\n",
    "        for key, value in d.items():\n",
    "            key_value_counter[key][value] += 1  # Count value occurrences per key\n",
    "\n",
    "    return key_value_counter\n",
    "\n",
    "key_value_counts_real = count_value_frequencies(list_of_comp_real)\n",
    "key_value_counts_sim = count_value_frequencies(list_of_comp_sim)\n",
    "\n",
    "# Print results\n",
    "for key, counter in key_value_counts_real.items():\n",
    "    print(f\"Key: {key}\")\n",
    "    for value, freq in counter.most_common():  # Sorted by frequency\n",
    "        freq_sim = key_value_counts_sim[key][value]\n",
    "        print(f\"  Value: {value}\\t freq-real: {freq} freq_sim: {freq_sim}\")\n",
    "    for value, freq_sim in key_value_counts_sim[key].items():\n",
    "        if value not in counter:\n",
    "            print(f\"  Value: {value}\\t freq-real: {0} freq_sim: {freq_sim}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 12 * 1/4))  # 1x3 grid of histograms\n",
    "axes = axes.flatten()  # Flatten axes for easy iteration\n",
    "# Plotting histograms for each POS\n",
    "for i, (pos, real_counts) in enumerate(key_value_counts_real.items()):\n",
    "    # Extract values and their frequencies\n",
    "    all_keys = list(set(real_counts.keys()).union(set(key_value_counts_sim[pos].keys())))\n",
    "\n",
    "\n",
    "    real_freq = [key_value_counts_real[pos].get(value, 0) for value in all_keys]\n",
    "    sim_freq = [key_value_counts_sim[pos].get(value, 0) for value in all_keys]\n",
    "    \n",
    "    # Get the current axis for plotting\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Bar width\n",
    "    width = 0.35  \n",
    "    x = range(len(all_keys))\n",
    "    \n",
    "    # Create bars for real frequencies and simulated frequencies\n",
    "    ax.bar(x, real_freq, width, label='Real Freq.',  alpha=0.7)\n",
    "    ax.bar(x, sim_freq, width, label='Sim. Freq.',  alpha=0.7)\n",
    "    \n",
    "    # Labels and Title\n",
    "    ax.set_xlabel('Text')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    #ax.set_title(f'{pos.capitalize()} Frequency')\n",
    "    ax.set_ylabel(f'{pos.capitalize()} Frequency')\n",
    "    ax.set_xticks([i for i in x])\n",
    "    ax.set_xticklabels(all_keys, rotation=90)\n",
    "    ax.legend()\n",
    "plt.tight_layout()  # Adjust layout for better spacing\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Similar Texts\n",
    "\n",
    "TOOD(maxim): Make a function to generate texts that mirror the original dataset\n",
    "\n",
    "(We want to simplify the original dataset .lower(), no . at the end, no space at the end)\n",
    "\n",
    "1. Option 1: define some templates + frequency\n",
    "2. Option 2: cout word freqeuncy and follow `/ManiSkill/mani_skill/examples/utils_env_interventions.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(texts))\n",
    "print(len(set(texts)))\n",
    "print(set(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Angles\n",
    "\n",
    "TODO(maxim): The angle distribution should be similar. Find out why they are different, is it because of the data or (hopelfully) because of a shift between the coordinate systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fig = plt.figure()\n",
    "# axes = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# names = \"real\", \"sim\"\n",
    "# data = (suffix_rs, suffix_ss)\n",
    "# for i in range(2):\n",
    "#     axes.scatter(data[i][:,3], data[i][:,4],data[i][:,5], alpha=0.5, label=names[i])\n",
    "#     #axes.scatter(data[i][:,9], data[i][:,10],data[i][:,11],alpha=0.7, label=names[i]+\"-dst\")\n",
    "#     axes.legend()\n",
    "# plt.show()\n",
    "\n",
    "from math import pi\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 12*1/4))\n",
    "names = \"real\", \"sim\"\n",
    "data = (suffix_rs, suffix_ss)\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        axes[j].hist(data[i][:,3+j], label=names[i], alpha=.7)\n",
    "        #axes[j].hist(data[i][:,3+j]/100-pi, alpha=0.7, label=names[i])\n",
    "        #axes[0].scatter(data[i][:,6], data[i][:,7], alpha=0.7, label=names[i]+\"-dst\")\n",
    "        axes[j].legend()\n",
    "    j = 3\n",
    "    norm = np.linalg.norm(data[i][:,3:6]/100-pi, axis=1)\n",
    "    axes[j].hist(norm, label=names[i], alpha=.7)\n",
    "    axes[j].legend()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot angles to gripper\n",
    "# https://stackoverflow.com/questions/31768031/plotting-points-on-the-surface-of-a-sphere\n",
    "\n",
    "from cvla.utils_traj_tokens import getActionEncDecFunction, decode_caption_xyzrotvec\n",
    "from cvla.utils_trajectory import DummyCamera\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import torch\n",
    "\n",
    "enc, dec = getActionEncDecFunction('xyzrotvec-cam-proj')\n",
    "camera = DummyCamera(intrinsic_matrix=[], extrinsic_matrix=[], width=224, height=224)\n",
    "\n",
    "def rotation_to_spherical(rot: R):\n",
    "    \"\"\"\n",
    "    Convert a 3D rotation (given as a scipy Rotation object) into spherical coordinates.\n",
    "    Returns:\n",
    "    - azimuth (longitude) φ in radians\n",
    "    - elevation (latitude) θ in radians\n",
    "    - rotation angle α in radians\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert rotation to axis-angle representation\n",
    "    axis, angle = rot.as_rotvec(), np.linalg.norm(rot.as_rotvec())\n",
    "    # Normalize the rotation axis to ensure it's a unit vector\n",
    "    if np.isclose(angle, 0):  # Handle zero rotation case\n",
    "        return 0, 0, 0\n",
    "    unit_axis = axis / angle  # Normalize axis to lie on unit sphere\n",
    "    x, y, z = unit_axis\n",
    "    # Compute spherical coordinates\n",
    "    azimuth = np.arctan2(y, x)  # Longitude φ\n",
    "    elevation = np.arcsin(z)     # Latitude θ\n",
    "    return azimuth, elevation, angle  # (φ, θ, α)\n",
    "\n",
    "datasets = (real_dataset, sim_dataset)\n",
    "dataset_names = (\"real\", \"sim\")\n",
    "sphericals = ([], [])\n",
    "\n",
    "limit = min([len(x) for x in datasets])\n",
    "for i in range(len(datasets)):\n",
    "    for j in range(len(datasets[i])):    \n",
    "        suffix = datasets[i][j][1][\"suffix\"]\n",
    "        dec_gt = decode_caption_xyzrotvec(suffix, camera)\n",
    "        orns_R = R.from_quat(dec_gt[1][:2], scalar_first=True)\n",
    "        sphericals[i].append(rotation_to_spherical(orns_R[0]))\n",
    "        if j == limit -1:\n",
    "            break\n",
    "    \n",
    "sphericals = np.array(sphericals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(maxim): ideally this plot looks similar to the xy image position ones where sim is a superset of real.\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i in range(len(datasets)):\n",
    "    spherical_sim = sphericals[i]\n",
    "    ax.scatter(spherical_sim[:,0],spherical_sim[:,1], spherical_sim[:,2],s=20, label=dataset_names[i])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvla.utils_vis import render_example\n",
    "\n",
    "html_imgs = \"\"\n",
    "for i in tqdm(range(num_samples)):\n",
    "    image_r, label_real = real_dataset[i]\n",
    "    image_s, label_sim = sim_dataset[i]\n",
    "    html_imgs += render_example(image_r, label=label_real[\"suffix\"], prediction=None, text=label_real[\"prefix\"])\n",
    "    html_imgs += render_example(image_s, label=label_sim[\"suffix\"], prediction=None, text=label_sim[\"prefix\"])\n",
    "\n",
    "    if i > 10:\n",
    "        break\n",
    "plot_images = True\n",
    "if plot_images:\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(html_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
