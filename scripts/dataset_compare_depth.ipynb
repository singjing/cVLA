{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from cvla.data_loader_h5 import H5Dataset\n",
    "from cvla.data_loader_jsonl import JSONLDataset, ValidDataset\n",
    "from cvla.data_loader_images import ImageFolderDataset\n",
    "from cvla.data_augmentations import RandomizeBackgrounds, augment_image_rgb, complexify_text, DepthAugmentation\n",
    "\n",
    "return_depth = True\n",
    "depth_to_color = False\n",
    "dataset_location = \"/tmp/clevr-act-7-depth\"\n",
    "\n",
    "depth_augment = DepthAugmentation()\n",
    "sim_dataset = H5Dataset(dataset_location, return_depth=return_depth, augment_depth=depth_augment, depth_to_color=depth_to_color)\n",
    "#randomize_background = RandomizeBackgrounds(p=0.2, background_images = \"/tmp/indoorCVPR/Images\")\n",
    "#train_dataset = H5Dataset(dataset_location, augment_rgbds=randomize_background, augment_rgb=augment_image_rgb, augment_text=complexify_text)\n",
    "\n",
    "\n",
    "#dataset_location = Path(\"/tmp/clevr-act-7-depth\")\n",
    "#randomize_background = RandomizeBackgrounds(p=0.2, background_images = \"/tmp/indoorCVPR/Images\")\n",
    "#train_dataset = H5Dataset(dataset_location, augment_rgbds=randomize_background, augment_rgb=augment_image_rgb)\n",
    "\n",
    "#dataset_location = \"/data/lmbraid19/argusm/datasets/cvla-droid-1of5c-v1\"\n",
    "#train_dataset = JSONLDataset(dataset_location, return_depth=return_depth)\n",
    "\n",
    "dataset_location = \"/data/lmbraid19/argusm/datasets/cvla-droid-block-v3\"\n",
    "real_dataset = JSONLDataset(dataset_location, return_depth=return_depth, depth_to_color=depth_to_color)\n",
    "\n",
    "plt.imshow(sim_dataset[0][0][0])\n",
    "print(\"dataset len\", len(real_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from tqdm.notebook import tqdm\n",
    "from cvla.utils_vis import render_example\n",
    "\n",
    "def get_image(images):\n",
    "    if isinstance(images, (list, tuple)):\n",
    "        return images[-1]\n",
    "    else:\n",
    "        return images\n",
    "    \n",
    "def get_depth(images):\n",
    "    if isinstance(images, (list, tuple)):\n",
    "        return images[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "print(\"Real Samples:\", len(real_dataset))\n",
    "num_samples = min(3*3, len(real_dataset))\n",
    "html_imgs = \"\"\n",
    "for i in tqdm(range(num_samples)):\n",
    "    images, sample = real_dataset[i]\n",
    "    image = get_image(images)\n",
    "    html_imgs += render_example(image, label=sample[\"suffix\"], text=sample[\"prefix\"], camera=sample[\"camera\"])\n",
    "    \n",
    "display(HTML(html_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Depth Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cvla.data_augmentations import depth_to_norm, norm_to_color\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "images, sample = real_dataset[0]\n",
    "real_depth_image = get_depth(images)\n",
    "if depth_to_color:\n",
    "    real_depth_image = (real_depth_image*255).round().astype(np.uint8)\n",
    "    real_depth_image = Image.fromarray(real_depth_image).resize((448,448))\n",
    "\n",
    "images, sample = sim_dataset[2]\n",
    "sim_depth_image = get_depth(images)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(8, 8*1/2))\n",
    "ax[0].imshow(np.clip(real_depth_image, 0, 1023))\n",
    "ax[1].imshow(np.clip(sim_depth_image, 0,1023))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def get_non_zero_min(arr):\n",
    "    return arr[arr!=0].min()\n",
    "\n",
    "real_mins = []\n",
    "sim_mins = []\n",
    "\n",
    "for i in tqdm(range(len(real_dataset))):\n",
    "    images, sample = real_dataset[i]\n",
    "    real_depth_image = get_depth(images)\n",
    "    real_mins.append(get_non_zero_min(real_depth_image))\n",
    "    images, sample = sim_dataset[i]\n",
    "    sim_depth_image = get_depth(images)\n",
    "    sim_mins.append(get_non_zero_min(sim_depth_image))\n",
    "\n",
    "plt.plot(sorted(real_mins), label=\"real\")\n",
    "plt.plot(sorted(sim_mins), label=\"sim\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "inspect.getfile(render_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "from tqdm.notebook import tqdm\n",
    "from cvla.data_augmentations import  color_to_norm, norm_to_depth\n",
    "\n",
    "results = {}\n",
    "for name, dataset in zip((\"real\", \"sim\"), (real_dataset, sim_dataset)):\n",
    "    num_samples = min(len(dataset), 160)\n",
    "    all_tcp_zs = []\n",
    "    all_depths = []\n",
    "    for i in tqdm(range(num_samples)):\n",
    "        (depth, image), sample = dataset[i]\n",
    "        #curve_25d, quat_c = decode_caption_xyzrotvec2(sample[\"suffix\"], sample[\"camera\"])\n",
    "        curve_25d, quat_c = dataset.action_encoder.decode_caption(sample[\"suffix\"], sample[\"camera\"])\n",
    "        x, y = curve_25d[0][:2].round().numpy().astype(int)\n",
    "        tcp_z_m = curve_25d[0][2].numpy()\n",
    "        x = np.clip(x, 0, depth.shape[1]-1)\n",
    "        y = np.clip(y, 0, depth.shape[0]-1)\n",
    "        if depth.ndim == 3:\n",
    "            image_depth_color = tuple(depth[y, x])\n",
    "            image_depth_norm = color_to_norm(image_depth_color)\n",
    "            image_depth_m = norm_to_depth(image_depth_norm) / 1000\n",
    "        else:\n",
    "            image_depth_m = depth[y, x] / 1000\n",
    "\n",
    "        if image_depth_m == 0:\n",
    "            continue\n",
    "        all_tcp_zs.append(tcp_z_m)\n",
    "        all_depths.append(image_depth_m)\n",
    "    results[name] = dict(tcp_zs=np.array(all_tcp_zs), depths=np.array(all_depths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "for name, res in results.items():\n",
    "    m ,b = np.polyfit(res[\"tcp_zs\"], res[\"depths\"], 1)\n",
    "    print(f\"{name}\\t y={m:.4f} x + {b:.4f}\")\n",
    "    s = 100\n",
    "    if name == \"sim\":\n",
    "        offset_m = 0.05\n",
    "        offset_m = 0\n",
    "        ax.scatter(res[\"tcp_zs\"]*s,(res[\"depths\"]+offset_m)*s, label=name, alpha=.7)\n",
    "    else:\n",
    "        ax.scatter(res[\"tcp_zs\"]*s,res[\"depths\"]*s, label=name, alpha=.7)\n",
    "    ax.set_xlabel(\"TCP zs [cm]\")\n",
    "    ax.set_ylabel(\"image depth [cm]\")\n",
    "\n",
    "    ax.plot((.3*s,.8*s),(.3*s,.8*s), color='k')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows, cols = 2, 2\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 12*2/3))  # 3 rows x 4 columns of histograms\n",
    "for c in range(cols):\n",
    "    (depth, image), sample = real_dataset[c]\n",
    "    curve_25d, quat_c = decode_caption_xyzrotvec2(sample[\"suffix\"], sample[\"camera\"])\n",
    "    x,y = curve_25d[0][:2].round().numpy().astype(int)\n",
    "    depth_val = curve_25d[0][2].numpy()\n",
    "\n",
    "    if depth.ndim == 3:\n",
    "        depth_color = tuple(depth[y, x])\n",
    "        depth_norm_float = color_to_norm(depth_color)\n",
    "        depth_float = norm_to_depth(depth_norm_float)\n",
    "    else:\n",
    "        depth_float = depth[y, x] * 1023 / 10\n",
    "    \n",
    "    print(depth_float, depth_val)\n",
    "    \n",
    "    d = curve_25d[0][2]\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        image = np.array(image)\n",
    "\n",
    "    for r in range(rows//2):\n",
    "        axes[r][c].imshow(depth)\n",
    "        circle = plt.Circle((x, y), 20, color='magenta', fill=False)\n",
    "        axes[r][c].add_patch(circle)  # Add circle to the image subplot\n",
    "\n",
    "        axes[r][c].set_title(\"depth\")\n",
    "        axes[r+1][c].imshow(image)\n",
    "        axes[r+1][c].set_title(sample[\"prefix\"].split(\"<\")[0])\n",
    "        circle = plt.Circle((x, y), 20, color='magenta', fill=False)\n",
    "        axes[r+1][c].add_patch(circle)  # Add circle to the image subplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plane Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install open3d\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "depth_augment = DepthAugmentation()\n",
    "\n",
    "dataset = JSONLDataset(dataset_location, return_depth=return_depth, augment_depth=depth_augment, depth_to_color=False)\n",
    "sample = dataset[10]\n",
    "rgb_image = sample[0][1]\n",
    "depth_image = sample[0][0]\n",
    "width, height = rgb_image.size\n",
    "intrinsic = sample[1][\"camera\"].get_intrinsic_matrix()[0].numpy()\n",
    "camera = o3d.camera.PinholeCameraIntrinsic(width, height, intrinsic)\n",
    "\n",
    "color_as_img = o3d.geometry.Image(np.asarray(rgb_image))\n",
    "depth_as_img = o3d.geometry.Image((depth_image))\n",
    "rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_as_img, depth_as_img)\n",
    "pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, camera)\n",
    "\n",
    "nb_neighbors=20\n",
    "std_ratio=2.0\n",
    "cl, ind = pcd.remove_statistical_outlier(nb_neighbors=nb_neighbors, std_ratio=std_ratio)\n",
    "\n",
    "\n",
    "pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "o3d.visualization.draw_geometries([pcd], zoom=0.5)\n",
    "print(\"done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
